{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0, loss=2.2903\n",
      "#5000, loss=0.3736\n",
      "#10000, loss=0.3303\n",
      "#15000, loss=0.3128\n",
      "#20000, loss=0.3028\n",
      "#25000, loss=0.2958\n",
      "#30000, loss=0.2909\n",
      "#35000, loss=0.2873\n",
      "#40000, loss=0.2844\n",
      "#45000, loss=0.2820\n",
      "#50000, loss=0.2804\n",
      "#55000, loss=0.2790\n",
      "#60000, loss=0.2773\n",
      "#65000, loss=0.2760\n",
      "#70000, loss=0.2752\n",
      "#75000, loss=0.2746\n",
      "#80000, loss=0.2737\n",
      "#85000, loss=0.2727\n",
      "#90000, loss=0.2720\n",
      "#95000, loss=0.2719\n",
      "Accuracy: 0.9228\n",
      "Predictions: [7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Загружаем MNIST датасет - числа, написанные от руки\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "    # Задаем граф вычислений в тензорфлоу\n",
    "    # Плейсхолдеры - те места, куда будут подставляться значения входных-выходных переменных\n",
    "    x = tf.placeholder(\"float\", [None, 784])\n",
    "    y = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "    # Переменные - это веса нашего единственного слоя сети\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "    b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "    # Предсказание это линейное преобразование входного вектора.<br>\n",
    "    # До преобразования размерность 784\n",
    "    # После преобразования - 10\n",
    "    linear_prediction = tf.matmul(x, W) + b\n",
    "    scaled_prediction = tf.nn.softmax(linear_prediction) # Softmax\n",
    "\n",
    "    # Функция потерь - кросс энтропия. В двух словах не объясню почему так. \n",
    "    # Почитайте лучше википедию. Но она работает\n",
    "    loss_function = tf.losses.softmax_cross_entropy(y, linear_prediction)\n",
    "\n",
    "    # Оптимизатор у нас простой градиентный спуск\n",
    "    learning_rate = 0.01\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_function)\n",
    "\n",
    "    # Инициализируем сессию, с которой будем работать\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.InteractiveSession()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Цикл обучения. Учимся на минибатчах, каждые 5 шагов печатаем ошибку\n",
    "    batch_size = 100\n",
    "\n",
    "    for iteration in range(100000):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer, \n",
    "                 feed_dict={x: batch_x, y: batch_y})\n",
    "        if iteration % 5000 == 0:\n",
    "            loss = loss_function.eval(\n",
    "                {x: mnist.test.images, \n",
    "                 y: mnist.test.labels})\n",
    "            print (\"#{}, loss={:.4f}\".format(iteration, loss))\n",
    "\n",
    "    # Задаем граф вычислений, выдающий точность предсказания\n",
    "    predicted_label = tf.argmax(scaled_prediction, 1)\n",
    "    actual_label = tf.argmax(y, 1)\n",
    "    is_equal_labels = tf.equal(actual_label, predicted_label)\n",
    "    accuracy = tf.reduce_mean(tf.cast(is_equal_labels, \"float\"))\n",
    "\n",
    "    # Вычисляем точность\n",
    "    accracy_value = accuracy.eval({x: mnist.test.images, y: mnist.test.labels})\n",
    "    print (\"Accuracy:\", accracy_value)\n",
    "\n",
    "    # Предсказываем лейбы для тествого датасета\n",
    "    predicted_label = tf.argmax(scaled_prediction, 1)\n",
    "    predicted_test_values = predicted_label.eval(\n",
    "        {x: mnist.test.images})\n",
    "    print (\"Predictions: {}\".format(predicted_test_values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
